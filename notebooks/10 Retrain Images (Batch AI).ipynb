{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Azure ML SDK installation and get version number for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Resource group: \", ws.resource_group)\n",
    "print(\"Location: \", ws.location)\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Experiment\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'image-retraining'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Batch AI cluster (GPU-enabled) as a compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'myazbai'\n",
    "\n",
    "try:\n",
    "    batch_ai_compute = BatchAiCompute(workspace=ws, name=compute_target_name)\n",
    "    print('found existing:', batch_ai_compute.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    batch_ai_config = BatchAiCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_NC6\",\n",
    "        vm_priority=\"dedicated\",\n",
    "        autoscale_enabled = True,\n",
    "        cluster_min_nodes = 0,\n",
    "        cluster_max_nodes = 4\n",
    "    )\n",
    "    batch_ai_compute = BatchAiCompute.create(\n",
    "        ws, \n",
    "        name=compute_target_name, \n",
    "        provisioning_configuration=batch_ai_config\n",
    "    )\n",
    "    batch_ai_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data files into datastore\n",
    "Every workspace comes with a default datastore (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and access it from the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Datastore name: \", ds.name)\n",
    "print(\"Datastore type: \", ds.datastore_type)\n",
    "print(\"Account name: \", ds.account_name)\n",
    "print(\"Container name: \", ds.container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unpack flower images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "tmp_path = '../tmp/image_retraining'\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "print('Downloading flower photos...')\n",
    "urllib.request.urlretrieve(\"http://download.tensorflow.org/example_images/flower_photos.tgz\", tmp_path + \"/flower_photos.tgz\")\n",
    "print('Unpacking archive...')\n",
    "shutil.unpack_archive(tmp_path + '/flower_photos.tgz', tmp_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload files to the datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tmp_path + '/flower_photos/'\n",
    "for (dirpath, dirnames, filenames) in os.walk(images_path):\n",
    "    print('Uploading', dirpath, '...')\n",
    "    ds.upload_files(\n",
    "        [dirpath + '/' + f for f in filenames], \n",
    "        target_path=dirpath.replace(tmp_path + '/', ''), \n",
    "        overwrite=True\n",
    "    )\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = '../projects/image_retraining'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('./scripts/retrain.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TensorFlow estimator\n",
    "The AML SDK's TensorFlow estimator enables you to easily submit TensorFlow training jobs for both single-node and distributed runs. For more information on the TensorFlow estimator, refer [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "script_params={\n",
    "    '--image_dir': str(ds.as_download()),\n",
    "    '--summaries_dir': './logs',\n",
    "    '--output_graph': './outputs/output_graph.pb',\n",
    "    '--output_labels': './outputs/output_labels.txt',\n",
    "    '--saved_model_dir': './outputs/model'\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory=project_folder,\n",
    "                       source_directory_data_store=ds,\n",
    "                       compute_target=batch_ai_compute,\n",
    "                       script_params=script_params,\n",
    "                       entry_script='retrain.py',\n",
    "                       pip_packages=['tensorflow_hub'],\n",
    "                       node_count=1,\n",
    "                       use_gpu=True)\n",
    "\n",
    "# Overwrite data store reference\n",
    "dr = DataReferenceConfiguration(\n",
    "    datastore_name=ds.name, \n",
    "    path_on_datastore='flower_photos', \n",
    "    mode='download', # download files from datastore to compute target\n",
    "    overwrite=True\n",
    ")\n",
    "estimator.run_config.data_references['workspacefilestore'] = dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = run.get_status()\n",
    "while status != 'Completed' and status != 'Failed':\n",
    "    print('current status: {} - waiting...'.format(run.get_status()))\n",
    "    time.sleep(10)\n",
    "    status = run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path = '../outputs/image_retraining'\n",
    "\n",
    "os.makedirs(outputs_path, exist_ok=True)\n",
    "\n",
    "for filename in run.get_file_names():\n",
    "    if filename.startswith('outputs'):\n",
    "        print(\"downloading\", filename, '...')\n",
    "        run.download_file(\n",
    "            filename, \n",
    "            output_file_path=outputs_path + filename.replace('outputs/','/')\n",
    "        )\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "python scripts/label_image.py \\\n",
    "--graph=../outputs/image_retraining/output_graph.pb \\\n",
    "--labels=../outputs/image_retraining//output_labels.txt \\\n",
    "--input_layer=Placeholder \\\n",
    "--output_layer=final_result \\\n",
    "--image=./resources/test-images/Daisy1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "python scripts/label_image.py \\\n",
    "--graph=../outputs/image_retraining/output_graph.pb \\\n",
    "--labels=../outputs/image_retraining//output_labels.txt \\\n",
    "--input_layer=Placeholder \\\n",
    "--output_layer=final_result \\\n",
    "--image=./resources/test-images/Rose1.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop TensorBoard\n",
    "When you're done, make sure to call the stop() method of the Tensorboard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
